{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day32 - NLP | Word2Vec + Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from nltk import word_tokenize, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset : https://www.kaggle.com/kazanova/sentiment140\n",
    "# col_0 = target \n",
    "# col_5 = text\n",
    "df = pd.read_csv('../dataset/twitter_SA.csv', encoding = 'ISO-8859-1', header=None)\n",
    "df = df[[0,5]]\n",
    "df.columns = ['target','text']\n",
    "\n",
    "# 0 = negative\n",
    "# 4 = positive -> 1\n",
    "df['target'] = df.target.apply(lambda x : 1 if x == 4 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(language=\"english\")\n",
    "\n",
    "# cleaning\n",
    "def clean_text(text):\n",
    "    \n",
    "    t = text.lower()                           # lowercase\n",
    "    t = re.sub(r\"[0-9]\",\"\",t)                  # remove digits\n",
    "    t = re.sub(r\"_\", \" \", t)\n",
    "    t = re.sub(r\"[^\\w\\s]\",\"\",t)\n",
    "    #t = re.sub(r\"https:\\/\\/[\\r\\n]*\",\"\", t) # remove link\n",
    "    #t = re.sub(r\"http:\\/\\/[\\r\\n]*\",\"\", t) # remove link\n",
    "    \n",
    "    tokens = word_tokenize(t)            # tokenization\n",
    "    stemmed_tokens = [stemmer.stem(tk) for tk in tokens if tk not in stopwords.words('english')]\n",
    "    \n",
    "    return stemmed_tokens\n",
    "\n",
    "df_test = df.sample(80000)\n",
    "df_test['text'] = df_test['text'].apply(lambda x : clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df_test.text\n",
    "y = df_test.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source : https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
    "phrases = Phrases(tweets, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x1c800333190>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4428121, 16851930)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source : https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial\n",
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('littl', 0.9998283982276917),\n",
       " ('hour', 0.9998264908790588),\n",
       " ('woke', 0.9998259544372559),\n",
       " ('hous', 0.9998244643211365),\n",
       " ('let', 0.999824047088623),\n",
       " ('next_week', 0.9998226165771484),\n",
       " ('yep', 0.999821662902832),\n",
       " ('train', 0.9998204112052917),\n",
       " ('drive', 0.9998199939727783),\n",
       " ('shit', 0.9998198747634888)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar('car', topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
